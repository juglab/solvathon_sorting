{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5b442c-7d05-4764-8315-30dd89d58ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839445fb-2e7c-40ba-a4c0-269763784e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/ashesh.ashesh/Documents/PhD/mbldata_solvation/data_with_tiff'\n",
    "use_features = ['SSC (Violet)-W', 'SSC (Imaging)-W', 'SSC (Violet)-A',\n",
    "       'Size (SSC (Imaging))', 'Diffusivity (SSC (Imaging))',\n",
    "       'SSC (Imaging)-A', 'Total Intensity (SSC (Imaging))', 'FSC-W',\n",
    "       'Size (FSC)', 'Diffusivity (FSC)', 'UV4 (440)-H', 'UV5 (460)-H',\n",
    "       'UV3 (420)-H', 'UV6 (475)-H', 'Diffusivity (Green*)', 'B4 (545)-H',\n",
    "       'UV5 (460)-W', 'UV4 (440)-W', 'UV6 (475)-W', 'B5 (575)-H']\n",
    "\n",
    "# load train data\n",
    "datatype = 'train'\n",
    "with open(os.path.join(datadir,f\"{datatype}_ds.bin\"), mode=\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "raw_train_data = data[f\"{datatype}_data\"]\n",
    "raw_train_labels = data[f\"{datatype}_labels\"]\n",
    "feature_names = data[\"feature_names\"]\n",
    "clean_mask = raw_train_data[:,-1] > 0\n",
    "# train_data  = raw_train_data[clean_mask,:].copy()\n",
    "# train_labels = raw_train_labels[clean_mask].copy()\n",
    "# 0, 1 have notiff\n",
    "# 2, 3 have tiff\n",
    "# 0,2 => label 0\n",
    "# 1,3 => label 1\n",
    "mask0 = np.logical_and(raw_train_labels == 0, raw_train_data[:,-1] == 0)\n",
    "mask1 = np.logical_and(raw_train_labels == 1, raw_train_data[:,-1] == 0)\n",
    "mask2 = np.logical_and(raw_train_labels == 0, raw_train_data[:,-1] == 1)\n",
    "mask3 = np.logical_and(raw_train_labels == 1, raw_train_data[:,-1] == 1)\n",
    "\n",
    "train_labels = -1 * np.ones(raw_train_labels.shape)\n",
    "train_labels[mask0] = 0\n",
    "train_labels[mask1] = 1\n",
    "train_labels[mask2] = 2\n",
    "train_labels[mask3] = 3\n",
    "assert set(np.unique(train_labels)) == set([0,1,2,3])\n",
    "assert np.sum(mask0 * mask1) ==0\n",
    "assert np.sum(mask0 * mask2) ==0\n",
    "assert np.sum(mask0 * mask3) ==0\n",
    "assert np.sum(mask1 * mask2) ==0\n",
    "assert np.sum(mask1 * mask3) ==0\n",
    "assert np.sum(mask2 * mask3) ==0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da4a6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    252617\n",
       "1.0     98628\n",
       "2.0      2527\n",
       "3.0      8482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_labels).value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d54287c6",
   "metadata": {},
   "source": [
    "C6818 is 0\n",
    "Emiliana is 1, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a9d39cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255144\n",
       "1    107110\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(raw_train_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cac1936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    252617\n",
       "1.0     98628\n",
       "3.0      8482\n",
       "2.0      2527\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86776549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan features: ['PlateLocationY']\n",
      "Used features: ['SSC (Violet)-W', 'SSC (Imaging)-W', 'SSC (Violet)-A', 'Size (SSC (Imaging))', 'Diffusivity (SSC (Imaging))', 'SSC (Imaging)-A', 'Total Intensity (SSC (Imaging))', 'FSC-W', 'Size (FSC)', 'Diffusivity (FSC)', 'UV4 (440)-H', 'UV5 (460)-H', 'UV3 (420)-H', 'UV6 (475)-H', 'Diffusivity (Green*)', 'B4 (545)-H', 'UV5 (460)-W', 'UV4 (440)-W', 'UV6 (475)-W', 'B5 (575)-H']\n",
      "(362254, 20) (362254,)\n"
     ]
    }
   ],
   "source": [
    "nan_feature_names = np.array(feature_names)[np.isnan(raw_train_data).any(axis=0)].tolist()\n",
    "nan_feature_names\n",
    "# unused_feature_idx = [feature_names.index(f) for f in nan_feature_names]\n",
    "# unused_feature_idx += [feature_names.index(f) for f in unused_features]\n",
    "used_feature_idx = [feature_names.index(f) for f in use_features] if use_features is not None else None\n",
    "\n",
    "print('Nan features:', nan_feature_names)\n",
    "# print('Unused features:', unused_features)\n",
    "if use_features is not None:\n",
    "    print('Used features:', use_features)\n",
    "    unused_feature_idx  = []\n",
    "\n",
    "\n",
    "def get_used_feature_idx():\n",
    "    if used_feature_idx is not None:\n",
    "        return used_feature_idx\n",
    "    \n",
    "    valid_feature_idx = []\n",
    "    for i in range(len(feature_names)):\n",
    "        if i not in unused_feature_idx:\n",
    "            valid_feature_idx.append(i)\n",
    "    return valid_feature_idx\n",
    "\n",
    "def remove_unused_features(input_data):\n",
    "    valid_feature_idx = get_used_feature_idx()\n",
    "    input_data = input_data[:, valid_feature_idx]\n",
    "    print(input_data.shape, train_labels.shape)\n",
    "    return input_data\n",
    "\n",
    "# train_data = remove_unused_features(train_data)\n",
    "train_data = remove_unused_features(raw_train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c4f6ad8",
   "metadata": {},
   "source": [
    "## Just working with relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12b856de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.logical_or(mask2, mask3)\n",
    "train_data = train_data[mask,:]\n",
    "train_labels = train_labels[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5035c2ee-348c-4e6a-bb6c-196379811388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "(9909, 20) (1100, 20)\n"
     ]
    }
   ],
   "source": [
    "# get a validation set\n",
    "random_indices = np.random.choice(len(train_data), len(train_data), replace=False)\n",
    "val_N = int(0.1*len(train_data))\n",
    "print(val_N)\n",
    "valid_data = train_data[random_indices[-val_N:]]\n",
    "valid_labels = train_labels[random_indices[-val_N:]]\n",
    "\n",
    "train_data = train_data[random_indices[:-val_N]]\n",
    "train_labels = train_labels[random_indices[:-val_N]]\n",
    "\n",
    "print(train_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99ffaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X = normalizer.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8f20149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_svm(f1_idx, f2_idx, filtered_X, filtered_labels):\n",
    "    svm0 = SVC(kernel='linear', probability=True)\n",
    "    print('in train_one_svm', filtered_X.shape)\n",
    "    svm0.fit(filtered_X[:,[f1_idx,f2_idx]], filtered_labels)\n",
    "    return svm0\n",
    "\n",
    "def get_filter_mask(svm, cur_X, target_idx):\n",
    "    mask = svm.predict(cur_X) == target_idx\n",
    "    return mask\n",
    "\n",
    "def get_filtered_training_data(svm, cur_X, cur_y, fidx_tuple, target_idx):\n",
    "    mask = get_filter_mask(svm, cur_X[:,fidx_tuple], target_idx)\n",
    "    return cur_X[mask,:], cur_y[mask]\n",
    "\n",
    "def get_prediction(svm_list,feature_idx_list, cur_X, target_idx):\n",
    "    output = np.ones(len(cur_X)) * -955\n",
    "    for svm, fidx_tuple in zip(svm_list, feature_idx_list):\n",
    "        cur_pred = svm.predict(cur_X[:,fidx_tuple])\n",
    "        everythingelsemask = cur_pred != target_idx\n",
    "        output[everythingelsemask] = 0\n",
    "    \n",
    "    output[output != 0] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cec38a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (9909, 20)\n",
      "in train_one_svm (9909, 20)\n",
      "3.0    7663\n",
      "2.0    2246\n",
      "dtype: int64\n",
      "Training data (7840, 20)\n",
      "in train_one_svm (7840, 20)\n",
      "3.0    7593\n",
      "2.0     247\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n",
      "Training data (7756, 20)\n",
      "in train_one_svm (7756, 20)\n",
      "3.0    7592\n",
      "2.0     164\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "target_idx = 3\n",
    "feature_idx_list = [(13,14), (0,1), (2,3), (3,4), (5,6), (7,8), (9,10), (11,12), (13,14), (15,16), (17,18)]\n",
    "svm_list = []\n",
    "cur_X = X\n",
    "cur_y = train_labels\n",
    "for fidx_tuple in feature_idx_list:\n",
    "    print('Training data', cur_X.shape)\n",
    "    svm = train_one_svm(fidx_tuple[0], fidx_tuple[1], cur_X, cur_y)\n",
    "    print(pd.Series(cur_y).value_counts())\n",
    "    svm_list.append(svm)\n",
    "    cur_X,cur_y = get_filtered_training_data(svm, cur_X, cur_y, fidx_tuple, target_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3d1e74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9762841860934504"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = get_prediction(svm_list,feature_idx_list, X, target_idx)\n",
    "np.mean(pred == (train_labels==target_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f36cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = svm0.coef_[0]   \n",
    "b = svm0.intercept_[0]     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planktons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d1c7b4c243dd1c68619aabfaac60ec6fd8a3adf74a792e780ecdff7dc65c27c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
