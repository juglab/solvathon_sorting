{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd5b442c-7d05-4764-8315-30dd89d58ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "839445fb-2e7c-40ba-a4c0-269763784e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = '/Users/ashesh.ashesh/Documents/PhD/mbldata_solvation/data_with_tiff'\n",
    "use_features = ['SSC (Violet)-W', 'SSC (Imaging)-W', 'SSC (Violet)-A',\n",
    "       'Size (SSC (Imaging))', 'Diffusivity (SSC (Imaging))',\n",
    "       'SSC (Imaging)-A', 'Total Intensity (SSC (Imaging))', 'FSC-W',\n",
    "       'Size (FSC)', 'Diffusivity (FSC)', 'UV4 (440)-H', 'UV5 (460)-H',\n",
    "       'UV3 (420)-H', 'UV6 (475)-H', 'Diffusivity (Green*)', 'B4 (545)-H',\n",
    "       'UV5 (460)-W', 'UV4 (440)-W', 'UV6 (475)-W', 'B5 (575)-H']\n",
    "\n",
    "# load train data\n",
    "datatype = 'train'\n",
    "with open(os.path.join(datadir,f\"{datatype}_ds.bin\"), mode=\"rb\") as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "def get_data_with_masks(raw_data_dict):\n",
    "    raw_train_data = data[f\"{datatype}_data\"]\n",
    "    raw_train_labels = data[f\"{datatype}_labels\"]\n",
    "    feature_names = data[\"feature_names\"]\n",
    "    # clean_mask = raw_train_data[:,-1] > 0\n",
    "    # train_data  = raw_train_data[clean_mask,:].copy()\n",
    "    # train_labels = raw_train_labels[clean_mask].copy()\n",
    "    # 0, 1 have notiff\n",
    "    # 2, 3 have tiff\n",
    "    # 0,2 => label 0\n",
    "    # 1,3 => label 1\n",
    "    mask0 = np.logical_and(raw_train_labels == 0, raw_train_data[:,-1] == 0)\n",
    "    mask1 = np.logical_and(raw_train_labels == 1, raw_train_data[:,-1] == 0)\n",
    "    mask2 = np.logical_and(raw_train_labels == 0, raw_train_data[:,-1] == 1)\n",
    "    mask3 = np.logical_and(raw_train_labels == 1, raw_train_data[:,-1] == 1)\n",
    "\n",
    "    train_labels = -1 * np.ones(raw_train_labels.shape)\n",
    "    train_labels[mask0] = 0\n",
    "    train_labels[mask1] = 1\n",
    "    train_labels[mask2] = 2\n",
    "    train_labels[mask3] = 3\n",
    "    assert set(np.unique(train_labels)) == set([0,1,2,3])\n",
    "    assert np.sum(mask0 * mask1) ==0\n",
    "    assert np.sum(mask0 * mask2) ==0\n",
    "    assert np.sum(mask0 * mask3) ==0\n",
    "    assert np.sum(mask1 * mask2) ==0\n",
    "    assert np.sum(mask1 * mask3) ==0\n",
    "    assert np.sum(mask2 * mask3) ==0\n",
    "\n",
    "    return {'X':raw_train_data, 'y':train_labels, 'feature_names':feature_names, 'masks': [mask0, mask1, mask2, mask3]}\n",
    "\n",
    "train_data_dict = get_data_with_masks(data)\n",
    "raw_train_data = train_data_dict['X']\n",
    "train_labels = train_data_dict['y']\n",
    "feature_names = train_data_dict['feature_names']\n",
    "mask0, mask1, mask2, mask3 = train_data_dict['masks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5da4a6f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    252617\n",
       "1.0     98628\n",
       "2.0      2527\n",
       "3.0      8482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(train_labels).value_counts().sort_index()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d54287c6",
   "metadata": {},
   "source": [
    "C6818 is 0\n",
    "Emiliana is 1, \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86776549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nan features: ['PlateLocationY']\n",
      "Used features: ['SSC (Violet)-W', 'SSC (Imaging)-W', 'SSC (Violet)-A', 'Size (SSC (Imaging))', 'Diffusivity (SSC (Imaging))', 'SSC (Imaging)-A', 'Total Intensity (SSC (Imaging))', 'FSC-W', 'Size (FSC)', 'Diffusivity (FSC)', 'UV4 (440)-H', 'UV5 (460)-H', 'UV3 (420)-H', 'UV6 (475)-H', 'Diffusivity (Green*)', 'B4 (545)-H', 'UV5 (460)-W', 'UV4 (440)-W', 'UV6 (475)-W', 'B5 (575)-H']\n",
      "(362254, 20) (362254,)\n"
     ]
    }
   ],
   "source": [
    "nan_feature_names = np.array(feature_names)[np.isnan(raw_train_data).any(axis=0)].tolist()\n",
    "nan_feature_names\n",
    "# unused_feature_idx = [feature_names.index(f) for f in nan_feature_names]\n",
    "# unused_feature_idx += [feature_names.index(f) for f in unused_features]\n",
    "used_feature_idx = [feature_names.index(f) for f in use_features] if use_features is not None else None\n",
    "\n",
    "print('Nan features:', nan_feature_names)\n",
    "# print('Unused features:', unused_features)\n",
    "if use_features is not None:\n",
    "    print('Used features:', use_features)\n",
    "    unused_feature_idx  = []\n",
    "\n",
    "\n",
    "def get_used_feature_idx():\n",
    "    if used_feature_idx is not None:\n",
    "        return used_feature_idx\n",
    "    \n",
    "    valid_feature_idx = []\n",
    "    for i in range(len(feature_names)):\n",
    "        if i not in unused_feature_idx:\n",
    "            valid_feature_idx.append(i)\n",
    "    return valid_feature_idx\n",
    "\n",
    "def remove_unused_features(input_data):\n",
    "    valid_feature_idx = get_used_feature_idx()\n",
    "    input_data = input_data[:, valid_feature_idx]\n",
    "    print(input_data.shape, train_labels.shape)\n",
    "    return input_data\n",
    "\n",
    "# train_data = remove_unused_features(train_data)\n",
    "train_data = remove_unused_features(raw_train_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c4f6ad8",
   "metadata": {},
   "source": [
    "## Just working with relevant data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "21828ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "08c51b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subsampling the positive class\n"
     ]
    }
   ],
   "source": [
    "all_masks = [mask0, mask1, mask2, mask3]\n",
    "pos_mask = all_masks[target_idx]\n",
    "posN = min(np.sum(pos_mask), max(np.sum(mask2), np.sum(mask3)))\n",
    "if posN < pos_mask.sum():\n",
    "    print('subsampling the positive class')\n",
    "    pos_idx = np.random.choice(np.where(pos_mask)[0], size=posN)\n",
    "    big_pos_mask = pos_mask.copy()\n",
    "    pos_mask = np.zeros_like(pos_mask) != 0\n",
    "    pos_mask[pos_idx] = True\n",
    "    \n",
    "neg_idx_list = []\n",
    "for idx in range(4):\n",
    "    if idx == target_idx:\n",
    "        continue\n",
    "    neg_mask = all_masks[idx]\n",
    "    neg_idx_list.append(np.random.choice(np.where(mask0)[0], size= posN//3))\n",
    "\n",
    "neg_idx = np.concatenate(neg_idx_list)\n",
    "\n",
    "neg_mask = np.zeros_like(pos_mask) != 0\n",
    "neg_mask[neg_idx] = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "12b856de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16464, 20)\n"
     ]
    }
   ],
   "source": [
    "assert np.logical_and(pos_mask, neg_mask).sum() ==0\n",
    "mask = np.logical_or(pos_mask, neg_mask)\n",
    "\n",
    "cur_train_data = train_data[mask,:]\n",
    "cur_train_labels = train_labels[mask]\n",
    "cur_train_labels = (cur_train_labels == target_idx ).astype(int)\n",
    "print(cur_train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5035c2ee-348c-4e6a-bb6c-196379811388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1646\n",
      "(14818, 20) (1646, 20)\n"
     ]
    }
   ],
   "source": [
    "# get a validation set\n",
    "random_indices = np.random.choice(len(cur_train_data), len(cur_train_data), replace=False)\n",
    "val_N = int(0.1*len(cur_train_data))\n",
    "print(val_N)\n",
    "valid_data = cur_train_data[random_indices[-val_N:]]\n",
    "cur_valid_labels = cur_train_labels[random_indices[-val_N:]]\n",
    "\n",
    "cur_train_data = cur_train_data[random_indices[:-val_N]]\n",
    "cur_train_labels = cur_train_labels[random_indices[:-val_N]]\n",
    "\n",
    "print(cur_train_data.shape, valid_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99ffaee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "normalizer = StandardScaler()\n",
    "X = normalizer.fit_transform(cur_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8f20149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_svm(f1_idx, f2_idx, filtered_X, filtered_labels):\n",
    "    svm0 = SVC(kernel='linear', probability=True)\n",
    "    print('in train_one_svm', filtered_X.shape)\n",
    "    svm0.fit(filtered_X[:,[f1_idx,f2_idx]], filtered_labels)\n",
    "    return svm0\n",
    "\n",
    "def get_filter_mask(svm, cur_X, target_idx):\n",
    "    mask = svm.predict(cur_X) == target_idx\n",
    "    return mask\n",
    "\n",
    "def get_filtered_training_data(svm, cur_X, cur_y, fidx_tuple):\n",
    "    mask = get_filter_mask(svm, cur_X[:,fidx_tuple], 1)\n",
    "    return cur_X[mask,:], cur_y[mask]\n",
    "\n",
    "def get_prediction(svm_list,feature_idx_list, cur_X):\n",
    "    target_idx = 1\n",
    "    output = np.ones(len(cur_X)) * -955\n",
    "    for svm, fidx_tuple in zip(svm_list, feature_idx_list):\n",
    "        cur_pred = svm.predict(cur_X[:,fidx_tuple])\n",
    "        everythingelsemask = cur_pred != target_idx\n",
    "        output[everythingelsemask] = 0\n",
    "    \n",
    "    output[output != 0] = 1\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ac4d7a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    847\n",
       "1    799\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(cur_valid_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cec38a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data (14818, 20)\n",
      "in train_one_svm (14818, 20)\n"
     ]
    }
   ],
   "source": [
    "feature_idx_list = [(0,1), (2,3), (3,4), (5,6), (7,8), (9,10), (11,12), (13,14), (15,16), (17,18)]\n",
    "svm_list = []\n",
    "cur_X = X\n",
    "cur_y = cur_train_labels\n",
    "for fidx_tuple in feature_idx_list:\n",
    "    print('Training data', cur_X.shape)\n",
    "    svm = train_one_svm(fidx_tuple[0], fidx_tuple[1], cur_X, cur_y)\n",
    "    print('Target', pd.Series(cur_y).value_counts())\n",
    "    svm_list.append(svm)\n",
    "    cur_X,cur_y = get_filtered_training_data(svm, cur_X, cur_y, fidx_tuple)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3d1e74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9566365837552279"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = get_prediction(svm_list,feature_idx_list, X)\n",
    "np.mean(pred == (cur_train_labels==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d4422440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2438\n",
       "1.0    2105\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "446b39cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(datadir,f\"test_ds.bin\"), mode=\"rb\") as f:\n",
    "    test_data_dict = pickle.load(f)\n",
    "\n",
    "test_data_dict = get_data_with_masks(data)\n",
    "raw_test_data = test_data_dict['X']\n",
    "test_labels = test_data_dict['y']\n",
    "# feature_names = test_data_dict['feature_names']\n",
    "# mask0, mask1, mask2, mask3 = test_data_dict['masks']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6de61c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(362254, 20) (362254,)\n"
     ]
    }
   ],
   "source": [
    "testX = normalizer.transform(remove_unused_features(raw_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b544ab79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9959834812037962"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = get_prediction(svm_list,feature_idx_list, testX)\n",
    "np.mean(pred == (test_labels==target_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60159b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "predtest_fname = f'testPrediction_class{target_idx}.npy'\n",
    "np.save(predtest_fname, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d69d9f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline_allFeatures_flexibleRange.ipynb\n",
      "\u001b[31mclassification.ipynb\u001b[m\u001b[m\n",
      "\u001b[31mclassification_4class.ipynb\u001b[m\u001b[m\n",
      "\u001b[31mdataset.ipynb\u001b[m\u001b[m\n",
      "gating_1.ipynb\n",
      "\u001b[31msvm_sequential_classification.ipynb\u001b[m\u001b[m\n",
      "testPrediction_class2.npy\n",
      "testPrediction_class3.npy\n"
     ]
    }
   ],
   "source": [
    "!ls ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f36cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w = svm0.coef_[0]   \n",
    "# b = svm0.intercept_[0]     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planktons",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "3d1c7b4c243dd1c68619aabfaac60ec6fd8a3adf74a792e780ecdff7dc65c27c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
